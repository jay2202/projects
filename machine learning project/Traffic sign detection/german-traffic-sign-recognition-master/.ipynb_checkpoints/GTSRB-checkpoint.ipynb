{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/isaimadoglu/german-traffic-sign-recognition/blob/isaWindows/GTSRB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "01mcSKau-il0"
   },
   "source": [
    "# **Training Part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "BKBqYm9QEYt9",
    "outputId": "29428e07-5b9c-4920-b075-105f5fbd7973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version Should be 2.1:  2.2.0\n",
      "Keras Version:  2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "# Pillow modulu de OpenCV gibi, basit bir goruntu isleme modulu\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(\"Tensorflow Version Should be 2.1: \", tf.__version__)\n",
    "print(\"Keras Version: \", keras.__version__)\n",
    "\n",
    "# Bunlar neural network kurulurken kullaniliyor\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D, Dropout, Dense\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# makine ogrenmesinde train ve test datalarini ayiran fonksiyon\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "colab_type": "code",
    "id": "fekiajXi-rqx",
    "outputId": "13a39527-4176-4367-cd52-bd3fcd0b3079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./gtsrb-dataset/Train/0/\n",
      "./gtsrb-dataset/Train/1/\n",
      "./gtsrb-dataset/Train/2/\n",
      "./gtsrb-dataset/Train/3/\n",
      "./gtsrb-dataset/Train/4/\n",
      "./gtsrb-dataset/Train/5/\n",
      "./gtsrb-dataset/Train/6/\n",
      "./gtsrb-dataset/Train/7/\n",
      "./gtsrb-dataset/Train/8/\n",
      "./gtsrb-dataset/Train/9/\n",
      "./gtsrb-dataset/Train/10/\n",
      "./gtsrb-dataset/Train/11/\n",
      "./gtsrb-dataset/Train/12/\n",
      "./gtsrb-dataset/Train/13/\n",
      "./gtsrb-dataset/Train/14/\n",
      "./gtsrb-dataset/Train/15/\n",
      "./gtsrb-dataset/Train/16/\n",
      "./gtsrb-dataset/Train/17/\n",
      "./gtsrb-dataset/Train/18/\n",
      "./gtsrb-dataset/Train/19/\n",
      "./gtsrb-dataset/Train/20/\n",
      "./gtsrb-dataset/Train/21/\n",
      "./gtsrb-dataset/Train/22/\n",
      "./gtsrb-dataset/Train/23/\n",
      "./gtsrb-dataset/Train/24/\n",
      "./gtsrb-dataset/Train/25/\n",
      "./gtsrb-dataset/Train/26/\n",
      "./gtsrb-dataset/Train/27/\n",
      "./gtsrb-dataset/Train/28/\n",
      "./gtsrb-dataset/Train/29/\n",
      "./gtsrb-dataset/Train/30/\n",
      "./gtsrb-dataset/Train/31/\n",
      "./gtsrb-dataset/Train/32/\n",
      "./gtsrb-dataset/Train/33/\n",
      "./gtsrb-dataset/Train/34/\n",
      "./gtsrb-dataset/Train/35/\n"
     ]
    }
   ],
   "source": [
    "# Reading the input images and putting them into a numpy array\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "# image size'leri 30x30 seklinde kucultmek icin kullanacagiz.\n",
    "height = 30\n",
    "width = 30\n",
    "# RGB icin\n",
    "channels = 3\n",
    "# sinif sayisi\n",
    "num_classes = 43\n",
    "\n",
    "# neural network input katmani icin??\n",
    "n_inputs = height * width*channels\n",
    "\n",
    "# NOT ALALIM\n",
    "for i in range(num_classes) :\n",
    "    path = \"./gtsrb-dataset/Train/{}/\".format(i)\n",
    "    Class=os.listdir(path)\n",
    "    \n",
    "    # For dongusu ile i'inci class'taki fotograflarin uzerinden geciyor.\n",
    "    for a in Class:\n",
    "        try:\n",
    "            image=cv2.imread(path+a) # siradaki image'i imread ile okuyor.\n",
    "            image_from_array = Image.fromarray(image, 'RGB')  # ???? https://pillow.readthedocs.io/en/3.1.x/reference/Image.html\n",
    "            size_image = image_from_array.resize((height, width))\n",
    "            # image'lar data list'ine numpy array olarak append ediliyor.\n",
    "            data.append(np.array(size_image))\n",
    "            labels.append(i) # etiketler '0, 1, 2, 3, .. ,42' seklinde\n",
    "        except AttributeError:\n",
    "            print(\"Error! goruntuyu alamadik.\")\n",
    "            \n",
    "x_train=np.array(data)\n",
    "# Her bir piksel 0-255 araliginda deger aliyor ya. Ben bu degerleri 0-1 araligina normalize etmek istersem ne yaparim? 255'e bolerim.\n",
    "x_train= x_train/255.0\n",
    "\n",
    "y_train=np.array(labels)\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes) # Using one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "hd4fCNzIBpFv",
    "outputId": "67500448-6ae1-4b9c-da7b-96017cbda371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (27446, 30, 30, 3)\n",
      "Valid : (11763, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X'ler veri, Y'ler label\n",
    "X_train,X_valid,Y_train,Y_valid = train_test_split(x_train,y_train,test_size = 0.3,random_state=0) # X_valid = X_test olarak dusunebiliriz\n",
    "print(\"Train :\", X_train.shape)\n",
    "print(\"Valid :\", X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "colab_type": "code",
    "id": "mXDnmSDAB7hF",
    "outputId": "756f3642-99fd-4947-f7d6-2f8171d34db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXhnLtaQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of this image is (30, 30, 3)\n",
      "Class of the image is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of this image is (30, 30, 3)\n",
      "Class of the image is [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxeY0Jig2pzFBsTmNCcr/Azf9+OPN7dGXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of this image is (30, 30, 3)\n",
      "Class of the image is [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Show Train images \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, labels, amount):\n",
    "    for i in range(amount):\n",
    "        index = int(random.random() * len(images))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[index])\n",
    "        plt.show()       \n",
    "        print(\"Size of this image is \" + str(images[index].shape))\n",
    "        print(\"Class of the image is \" + str(labels[index]))\n",
    "\n",
    "print(\"Train images\")\n",
    "show_images(X_train, Y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "JtO4BKB_B-PF",
    "outputId": "10eed7b1-66d7-4abf-f637-1b0e949e5ccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 879,691\n",
      "Trainable params: 879,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=X_train.shape[1:])) # input layer + convolution layer\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(num_classes, activation='softmax')) # class'i belirleyen layer\n",
    "\n",
    "model.summary() # ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZAx-K7TCCGl"
   },
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "rLhpDglCCEWN",
    "outputId": "58215e1b-dd5c-48c0-e69e-f370ad7fe0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27446 samples, validate on 11763 samples\n",
      "Epoch 1/10\n",
      "27446/27446 [==============================] - 142s 5ms/sample - loss: 1.5726 - accuracy: 0.5517 - val_loss: 0.2591 - val_accuracy: 0.9268\n",
      "Epoch 2/10\n",
      "27446/27446 [==============================] - 141s 5ms/sample - loss: 0.3571 - accuracy: 0.8859 - val_loss: 0.0908 - val_accuracy: 0.9749\n",
      "Epoch 3/10\n",
      "20096/27446 [====================>.........] - ETA: 34s - loss: 0.2101 - accuracy: 0.9356"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2054193ac1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "epochs = 10\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), batch_size=32, epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QYD4LslCGDW"
   },
   "outputs": [],
   "source": [
    "# plot the accuracy and the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGUpEmMmCKAP"
   },
   "outputs": [],
   "source": [
    "# Predicting Test data \n",
    "y_test=pd.read_csv(\"./Test.csv\")\n",
    "labels=y_test['Path'].as_matrix()\n",
    "y_test=y_test['ClassId'].values\n",
    "\n",
    "data=[]\n",
    "\n",
    "for f in labels:\n",
    "    image=cv2.imread('./test/'+f.replace('Test/', ''))\n",
    "    image_from_array = Image.fromarray(image, 'RGB')\n",
    "    size_image = image_from_array.resize((height, width))\n",
    "    data.append(np.array(size_image))\n",
    "\n",
    "X_test=np.array(data)\n",
    "X_test = X_test.astype('float32')/255  \n",
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvOomJHhCOAV"
   },
   "outputs": [],
   "source": [
    "# Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72N3JmrbCS7T"
   },
   "outputs": [],
   "source": [
    "print(\"pred: \", pred, \" Type: \", type(pred), \" shape: \", pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4h9G5V5WCU8C"
   },
   "outputs": [],
   "source": [
    "print(\"X_test: \", X_test, \" Type: \", type(X_test), \" shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE2TgDQ1CZGH"
   },
   "outputs": [],
   "source": [
    "first_in = 1\n",
    "second_in = 2\n",
    "class_of_prediction = model.predict_classes(X_test[first_in:second_in])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZRccJBcCars"
   },
   "outputs": [],
   "source": [
    "class_of_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAGQkGjlCc4E"
   },
   "outputs": [],
   "source": [
    "sinif = 1\n",
    "if(class_of_prediction == sinif):\n",
    "    print(\"Birinci Sinif\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMrCjMVoa7/EoFVzlMEyKEO",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GTSRB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
