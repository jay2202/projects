{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../tickets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9c08af255a69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../tickets.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../tickets.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../tickets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b74464c7faca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.intent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing punctuations and symbols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = '''()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "my_str = \"Hello!!!, he said ---and went.\"\n",
    "\n",
    "\n",
    "\n",
    "# remove punctuation from the string\n",
    "no_punct = \"\"\n",
    "for char in my_str:\n",
    "    if(char not in punctuations):\n",
    "        no_punct = no_punct + char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!!! he said and went'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "s = \"string. With. Punctuation?\"\n",
    "s = re.sub(r'[^\\w\\s]','',s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string With Punctuation'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[   #Character block start.\n",
    "^   #Not these characters (letters, numbers).\n",
    "\\w  #Word characters.\n",
    "\\s  #Space characters.\n",
    "]   #Character block end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'how', 'are', 'u']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(\"hi how are u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using python split\n",
    "s = 'hi how are you'\n",
    "s.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add or remove stopwords\n",
    "stop_words.append('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'work']\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there\n",
      "are\n",
      "sever\n",
      "type\n",
      "of\n",
      "stem\n",
      "algorithm\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "#from nltk.tokenize import word_tokenize\n",
    "stemmer= PorterStemmer()\n",
    "input_str=\"There are several types of stemming algorithms.\"\n",
    "input_str=nltk.word_tokenize(input_str)\n",
    "for word in input_str:\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been\n",
      "had\n",
      "done\n",
      "language\n",
      "city\n",
      "mouse\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "input_str=\"been had done languages cities mice\"\n",
    "input_str=nltk.word_tokenize(input_str)\n",
    "for word in input_str:\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the preprocessing on tickets datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Need', 'Ethernet', 'access']\n",
      "['Create', 'new', 'account', 'share', 'username', 'password']\n",
      "['FW', 'Myspace', 'Login', 'Issue', 'Ania']\n",
      "['Login', 'credetials', 'working']\n",
      "['New', 'Account', 'needed', 'new', 'joinee']\n",
      "['Request', 'configure', 'system', 'share', 'among', 'user']\n",
      "['Needs', 'permission', 'wifi', 'access', 'laptop']\n",
      "['LAN', 'working', 'VM']\n",
      "['Wifi', 'access', 'needed']\n",
      "['My', 'Space', 'QA', 'application']\n",
      "['Configure', 'outlook', 'system']\n",
      "['Install', 'postgres', 'database', 'machine']\n",
      "['System', 'showing', 'blue', 'screen', 'startup']\n",
      "['Desktop', 'working']\n",
      "['System', 'behaving', 'strangely', 'blue', 'screen', 'appearing', 'middle']\n",
      "['My', 'Internet', 'working']\n",
      "['Account', 'got', 'locked', '3', 'wrong', 'attempt', 'o', 'password', 'Could', 'please', 'reset', 'password']\n",
      "['System', 'hang', 'blue', 'screen', 'startup']\n",
      "['Unable', 'connect', 'Internet']\n",
      "['Facing', 'networkinternet', 'issue', 'wifi', 'xwq090']\n",
      "['Replace', 'battery', 'Macbook', 'laptop']\n",
      "['Computer', 'getting', 'switched']\n",
      "['Forgot', 'password', 'please', 'reset', 'password']\n",
      "['MySpace', 'Password', 'Expiry']\n",
      "['install', 'MS', 'office']\n",
      "['Password', 'expired']\n",
      "['Account', 'locked', 'Not', 'able', 'login']\n",
      "['Are', 'space', 'allowed', 'email', 'address']\n",
      "['Can', 'virus', 'damage', 'computer', 'hardware']\n",
      "['Does', 'Windows', 'come', 'virus', 'protection', 'program']\n",
      "['How', 'I', 'clean', 'keyboard']\n",
      "['How', 'I', 'recover', 'file', 'recycle', 'bin']\n",
      "['How', 'I', 'update', 'Microsoft', 'Windows', 'computer']\n",
      "['How', 'I', 'delete', 'Internet', 'cooky']\n",
      "['How', 'I', 'determine', 'computer', 'name']\n",
      "['How', 'I', 'fix', 'paper', 'jam']\n",
      "['How', 'I', 'get', 'safe', 'mode']\n",
      "['How', 'I', 'map', 'network', 'drive']\n",
      "['I', 'unable', 'send', 'receive', 'email']\n",
      "['I', 'cant', 'connect', 'network', 'drive', 'anymore']\n",
      "['I', 'cant', 'delete', 'file', 'used', 'Windows']\n",
      "['I', 'cant', 'receive', 'email', 'attachment']\n",
      "['I', 'get', 'signal', 'input', 'message', 'I']\n",
      "['I', 'lost', 'printer', 'installation', 'disk', 'I', 'install', 'printer']\n",
      "['If', 'I', 'format', 'erase', 'hard', 'drive', 'remove', 'virus']\n",
      "['Is', 'safe', 'turn', 'Windows', 'computer', 'without', 'shut']\n",
      "['My', 'Computer', 'doesnt', 'power']\n",
      "['My', 'Computer', 'freeze', 'behaving', 'strangely']\n",
      "['My', 'computer', 'turn', 'I']\n",
      "['My', 'printer', 'printing', 'smudgeddistorted', 'page']\n",
      "['Nothing', 'appears', 'Monitor']\n",
      "['The', 'wheel', 'mouse', 'isnt', 'working', 'properly', 'I']\n",
      "['There', 'black', 'border', 'screen', 'I']\n",
      "['There', 'display', 'monitor', 'I']\n",
      "['What', 'I', 'hard', 'disk', 'fails']\n",
      "['What', 'I', 'image', 'screen', 'distorted', 'skewed']\n",
      "['What', 'I', 'computer', 'crash']\n",
      "['What', 'computer', 'virus']\n",
      "['Why', 'mouse', 'acting', 'erratically']\n",
      "['A', 'new', 'account', 'required', 'new', 'client']\n",
      "['Are', 'space', 'allowed', 'email', 'address']\n",
      "['Blocked', 'account', 'Impossible', 'connect']\n",
      "['Can', 'virus', 'damage', 'computer', 'hardware']\n",
      "['Can', 'connect', 'Internet']\n",
      "['Compte', 'été', 'verrouillé', 'à', 'cause', 'de', '3', 'mauvaises', 'tentatives', 'o', 'mot', 'de', 'passe', 'Pourriezvous', 'réinitialiser', 'le', 'mot', 'de', 'passe']\n",
      "['Configure', 'Outlook', 'system']\n",
      "['Create', 'new', 'account', 'share', 'username', 'password']\n",
      "['Does', 'Windows', 'come', 'virus', 'protection', 'program']\n",
      "['FW', 'Connection', 'issue', 'Myspace', 'Ania']\n",
      "['Faced', 'network', 'internet', 'problem', 'wifi', 'xwq090']\n",
      "['Forgotten', 'password', 'please', 'reset', 'password']\n",
      "['How', 'I', 'clean', 'keyboard']\n",
      "['How', 'I', 'determine', 'name', 'computer']\n",
      "['How', 'I', 'enter', 'safe', 'mode']\n",
      "['How', 'I', 'recover', 'file', 'recycle', 'bin']\n",
      "['How', 'I', 'update', 'Microsoft', 'Windows', 'computer']\n",
      "['How', 'delete', 'Internet', 'cooky']\n",
      "['How', 'fix', 'paper', 'jam']\n",
      "['How', 'map', 'network', 'drive']\n",
      "['I', 'connect', 'network', 'drive', 'anymore']\n",
      "['I', 'delete', 'file', 'used', 'Windows']\n",
      "['I', 'receive', 'attachment']\n",
      "['I', 'send', 'receive', 'email']\n",
      "['I', 'lost', 'printer', 'installation', 'disc', 'I', 'install', 'printer']\n",
      "['I', 'receive', 'message', 'signal', 'input', 'I']\n",
      "['If', 'I', 'format', 'erase', 'hard', 'drive', 'remove', 'virus']\n",
      "['Install', 'postgres', 'database', 'machine']\n",
      "['Is', 'safe', 'turn', 'Windows', 'computer', 'without', 'shutting']\n",
      "['LAN', 'virtual', 'machine']\n",
      "['Login', 'credetials']\n",
      "['My', 'Internet']\n",
      "['My', 'computer', 'turn', 'I']\n",
      "['My', 'computer', 'turn']\n",
      "['My', 'computer', 'freeze', 'behaves', 'strangely']\n",
      "['My', 'mouse', 'wheel', 'working', 'properly', 'I']\n",
      "['My', 'printer', 'print', 'stained', 'distorted', 'page']\n",
      "['MySpace', 'Password', 'Expiry']\n",
      "['Need', 'Ethernet', 'access']\n",
      "['Need', 'authorization', 'wifi', 'access', 'laptop']\n",
      "['Nothing', 'appears', 'Monitor']\n",
      "['Password', 'expired']\n",
      "['Replace', 'battery', 'Macbook', 'laptop']\n",
      "['System', 'behaving', 'strangely', 'blue', 'screen', 'appears', 'middle']\n",
      "['System', 'configuration', 'request', 'share', 'user']\n",
      "['System', 'showing', 'blue', 'screen', 'startup']\n",
      "['The', 'My', 'Space', 'QA', 'app']\n",
      "['The', 'computer', 'turn']\n",
      "['The', 'office']\n",
      "['The', 'system', 'hang', 'blue', 'screen', 'startup']\n",
      "['There', 'black', 'border', 'screen', 'I']\n",
      "['There', 'display', 'monitor', 'I']\n",
      "['What', 'hard', 'drive']\n",
      "['What', 'computer', 'virus']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['What', 'image', 'screen', 'distorted', 'tilted']\n",
      "['What', 'computer', 'crash']\n",
      "['Why', 'mouse', 'act', 'erratically']\n",
      "['Wifi', 'access', 'required']\n",
      "['installer', 'MS', 'Office']\n",
      "['Are', 'space', 'allowed', 'email', 'address']\n",
      "['Blocked', 'account', 'I', 'log']\n",
      "['Can', 'virus', 'damage', 'computer', 'hardware']\n",
      "['Can', 'connect', 'Internet']\n",
      "['Configure', 'Outlook', 'system']\n",
      "['Create', 'new', 'account', 'share', 'username', 'password']\n",
      "['Does', 'Windows', 'come', 'virus', 'protection', 'program']\n",
      "['FW', 'Myspace', 'login', 'problem', 'Ania']\n",
      "['Facing', 'network', 'internet', 'problem', 'wifi', 'xwq090']\n",
      "['How', 'I', 'clean', 'keyboard']\n",
      "['How', 'I', 'recover', 'file', 'recycle', 'bin']\n",
      "['How', 'I', 'update', 'computer', 'Microsoft', 'Windows']\n",
      "['How', 'I', 'delete', 'Internet', 'cooky']\n",
      "['How', 'I', 'determine', 'name', 'computer']\n",
      "['How', 'I', 'fix', 'paper', 'jam']\n",
      "['How', 'I', 'get', 'safe', 'mode']\n",
      "['How', 'I', 'map', 'network', 'drive']\n",
      "['I', 'connect', 'network', 'drive', 'anymore']\n",
      "['I', 'delete', 'file', 'using', 'Windows']\n",
      "['I', 'receive', 'email', 'attachment']\n",
      "['I', 'send', 'receive', 'email']\n",
      "['I', 'forgot', 'password', 'reset', 'password']\n",
      "['I', 'lost', 'printer', 'installation', 'disk', 'I', 'install', 'printer']\n",
      "['I', 'receive', 'signal', 'input', 'message', 'I']\n",
      "['If', 'I', 'format', 'erase', 'hard', 'drive', 'eliminate', 'virus']\n",
      "['Install', 'postgres', 'database', 'machine']\n",
      "['Is', 'safe', 'turn', 'Windows', 'computer', 'without', 'closing']\n",
      "['LAN', 'VM']\n",
      "['La', 'cuenta', 'se', 'bloqueó', 'debido', '3', 'intentos', 'incorrectos', 'de', 'contraseña', 'Podrías', 'por', 'favor', 'reiniciar', 'la', 'contraseña']\n",
      "['Login', 'credential']\n",
      "['My', 'Internet']\n",
      "['My', 'computer', 'turn', 'I']\n",
      "['My', 'computer', 'turn']\n",
      "['My', 'computer', 'freeze', 'behaves', 'strangely']\n",
      "['My', 'printer', 'printing', 'stained', 'distorted', 'page']\n",
      "['MySpace', 'Password', 'Expiration']\n",
      "['New', 'account', 'necessary', 'new', 'member']\n",
      "['Nothing', 'appears', 'monitor']\n",
      "['Replace', 'battery', 'Macbook', 'laptop']\n",
      "['Request', 'configure', 'system', 'share', 'among', 'user']\n",
      "['System', 'show', 'blue', 'screen', 'beginning']\n",
      "['The', 'My', 'Space', 'QA', 'application', 'inactive']\n",
      "['The', 'computer', 'turn']\n",
      "['The', 'desktop']\n",
      "['The', 'password', 'expired']\n",
      "['The', 'system', 'behaves', 'strangely', 'blue', 'screen', 'appears', 'middle']\n",
      "['The', 'system', 'hang', 'blue', 'screen', 'start']\n",
      "['The', 'wheel', 'mouse', 'correctly', 'I']\n",
      "['There', 'black', 'border', 'screen', 'I']\n",
      "['There', 'screen', 'monitor', 'I']\n",
      "['What', 'I', 'hard', 'drive']\n",
      "['What', 'I', 'image', 'screen', 'distorted', 'skewed']\n",
      "['What', 'I', 'computer', 'crash']\n",
      "['What', 'computer', 'virus']\n",
      "['Why', 'mouse', 'acting', 'erratically']\n",
      "['Wifi', 'access', 'required']\n",
      "['You', 'need', 'Ethernet', 'access']\n",
      "['You', 'need', 'wifi', 'access', 'permission', 'laptop']\n",
      "['install', 'MS', 'office']\n",
      "['A', 'new', 'account', 'needed', 'new', 'participant']\n",
      "['Are', 'space', 'allowed', 'email', 'address']\n",
      "['Blocked', 'account', 'Do', 'log']\n",
      "['Can', 'virus', 'damage', 'computer', 'hardware']\n",
      "['Configure', 'Outlook', 'system']\n",
      "['Create', 'new', 'account', 'share', 'username', 'password']\n",
      "['FW', 'Myspace', 'Login', 'Problem', 'Ania']\n",
      "['Forgotten', 'password', 'please', 'reset', 'password']\n",
      "['Given', 'problem', 'network', 'Internet', 'Wifi', 'xwq090']\n",
      "['How', 'I', 'clean', 'keyboard']\n",
      "['How', 'I', 'recover', 'file', 'Recycle', 'Bin']\n",
      "['How', 'I', 'update', 'Microsoft', 'Windows', 'computer']\n",
      "['How', 'I', 'delete', 'internet', 'cooky']\n",
      "['How', 'I', 'find', 'name', 'computer']\n",
      "['How', 'I', 'fix', 'paper', 'jam']\n",
      "['How', 'I', 'get', 'safe', 'mode']\n",
      "['How', 'I', 'map', 'network', 'drive']\n",
      "['I', 'connect', 'network', 'drive', 'anymore']\n",
      "['I', 'delete', 'file', 'used', 'Windows']\n",
      "['I', 'receive', 'email', 'attachment']\n",
      "['I', 'send', 'receive', 'email']\n",
      "['I', 'get', 'signal', 'input', 'message', 'I']\n",
      "['I', 'lost', 'printer', 'installation', 'disk', 'How', 'I', 'install', 'printer']\n",
      "['If', 'I', 'format', 'delete', 'drive', 'remove', 'virus']\n",
      "['Install', 'MS', 'Office']\n",
      "['Install', 'Postgres', 'database', 'computer']\n",
      "['Is', 'Windows', 'equipped', 'antivirus', 'program']\n",
      "['Is', 'safe', 'turn', 'Windows', 'computer', 'without', 'shutting']\n",
      "['LAN', 'VM']\n",
      "['Login', 'credential']\n",
      "['My', 'Space', 'QA', 'application', 'available']\n",
      "['My', 'computer', 'power']\n",
      "['My', 'computer', 'freeze', 'behaves', 'strangely']\n",
      "['My', 'computer', 'turn', 'What', 'I']\n",
      "['My', 'internet', 'working']\n",
      "['My', 'printer', 'print', 'smeared', 'distorted', 'page']\n",
      "['MySpace', 'password', 'expiration']\n",
      "['Need', 'Ethernet', 'access']\n",
      "['No', 'connection', 'internet', 'possible']\n",
      "['Nothing', 'appears', 'monitor']\n",
      "['Password', 'expired']\n",
      "['Replace', 'battery', 'Macbook', 'laptop']\n",
      "['Request', 'system', 'configured', 'share', 'user']\n",
      "['Requires', 'permission', 'wifi', 'access', 'laptop']\n",
      "['System', 'behaves', 'strangely', 'blue', 'screen', 'appears', 'middle']\n",
      "['System', 'showing', 'blue', 'screen', 'startup']\n",
      "['The', 'account', 'blocked', 'due', '3', 'wrong', 'password', 'attempt', 'Could', 'please', 'reset', 'password']\n",
      "['The', 'computer', 'turn']\n",
      "['The', 'desktop', 'working']\n",
      "['The', 'system', 'hang', 'startup', 'blue', 'screen']\n",
      "['The', 'wheel', 'mouse', 'working', 'properly', 'I']\n",
      "['There', 'black', 'border', 'screen', 'I']\n",
      "['There', 'display', 'monitor', 'I']\n",
      "['What', 'I', 'computer', 'crash']\n",
      "['What', 'I', 'hard', 'drive']\n",
      "['What', 'I', 'image', 'screen', 'distorted', 'distorted']\n",
      "['What', 'computer', 'virus']\n",
      "['Why', 'mouse', 'behave', 'unpredictably']\n",
      "['WiFi', 'access', 'required']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "for index,row in data.iterrows():\n",
    "    filter_sentence = []\n",
    "    sentence = row['Title']\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence) #cleaning\n",
    "    words = nltk.word_tokenize(sentence) #tokenization\n",
    "    words = [w for w in words if not w in stop_words]  #stopwords removal\n",
    "    for word in words:\n",
    "        filter_sentence.append(lemmatizer.lemmatize(word))\n",
    "    print(filter_sentence)\n",
    "    data.ix[index,'Title'] = filter_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse and Improvise \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>of</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>way</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Count\n",
       "16   of      3\n",
       "26  the      3\n",
       "3   bow      2\n",
       "0   and      1\n",
       "28  way      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = \"In the-state-of-art of the NLP field, Embedding is the \\\n",
    "success way to resolve text related problem and outperform \\\n",
    "Bag of Words ( BoW ). Indeed, BoW introduced limitations \\\n",
    "large feature dimension, sparse representation etc.\"\n",
    "count_vec = CountVectorizer()\n",
    "count_occurs = count_vec.fit_transform([doc])\n",
    "count_occur_df = pd.DataFrame(\n",
    "    (count, word) for word, count in\n",
    "     zip(count_occurs.toarray().tolist()[0], \n",
    "    count_vec.get_feature_names()))\n",
    "count_occur_df.columns = ['Word', 'Count']\n",
    "count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
    "count_occur_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and this', 'document is', 'first document', 'is the', 'is this', 'second document', 'the first', 'the second', 'the third', 'third one', 'this document', 'this is', 'this the']\n",
      "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "print(vectorizer2.get_feature_names())\n",
    "print(X2.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t1\n",
      "  (0, 26)\t3\n",
      "  (0, 23)\t1\n",
      "  (0, 16)\t3\n",
      "  (0, 1)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 3)\t2\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 26)\t3\n",
      "  (0, 23)\t1\n",
      "  (0, 16)\t3\n",
      "  (0, 1)\t1\n",
      "  (0, 15)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 3)\t2\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "for i in count_occurs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
